import whisper
import google.generativeai as genai
import json
import time
from dotenv import load_dotenv
import os

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Whisper & Gemini ì´ˆê¸°í™”
print("Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
whisper_model = whisper.load_model("small")
print("âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

genai.configure(api_key=GOOGLE_API_KEY)
generation_config = {"temperature": 0.7, "max_output_tokens": 1024}
gemini_model = genai.GenerativeModel(
    model_name="gemini-2.0-flash-001",
    generation_config=generation_config
)


def transcribe_audio_with_whisper(audio_path: str):
    print("ğŸ§ Whisper ë³€í™˜ ì‹œì‘...")
    start = time.time()
    try:
        result = whisper_model.transcribe(audio_path, language="ko", fp16=False)
        elapsed = round(time.time() - start, 2)
        print(f"âœ… Whisper ë³€í™˜ ì™„ë£Œ ({elapsed}ì´ˆ)")
        return result["text"]
    except Exception as e:
        print(f"âŒ Whisper ì˜¤ë¥˜: {e}")
        return None


def generate_feedback_with_gemini(question, answer):
    print("ğŸ§  Gemini í”¼ë“œë°± ìƒì„± ì¤‘...")
    start = time.time()

    prompt = f"""
    ë©´ì ‘ ì§ˆë¬¸: "{question}"
    ë©´ì ‘ì ë‹µë³€: "{answer}"
    ---
    JSON í˜•ì‹ìœ¼ë¡œ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
    {{
      "feedback": "í•µì‹¬ ì‚¬ë¡€ë¥¼ ë¨¼ì € ì œì‹œí•˜ë©´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.",
      "confidence": 75,
      "tone": 68,
      "resilience": 80,
      "good": "êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì˜ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.",
      "bad": "ë‹µë³€ì´ ë‹¤ì†Œ ì¥í™©í–ˆìŠµë‹ˆë‹¤."
    }}
    """

    try:
        res = gemini_model.generate_content(prompt)
        txt = res.text.strip()
        if txt.startswith("```"):
            txt = txt.replace("```json", "").replace("```", "").strip()
        parsed = json.loads(txt)
        elapsed = round(time.time() - start, 2)
        print(f"âœ… Gemini í”¼ë“œë°± ì™„ë£Œ ({elapsed}ì´ˆ)")
        print(parsed)
        return parsed
    except Exception as e:
        print(f"âŒ Gemini ì˜¤ë¥˜: {e}")
        return {"feedback": "í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨", "confidence": 0, "tone": 0, "resilience": 0}


def run_interview_feedback_service(audio_path, interview_question):
    text = transcribe_audio_with_whisper(audio_path)
    if not text:
        return {"feedback": "ìŒì„± ë³€í™˜ ì‹¤íŒ¨", "confidence": 0, "tone": 0, "resilience": 0}
    print(f"ğŸ—£ï¸ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì¼ë¶€: {text[:100]}...")
    return generate_feedback_with_gemini(interview_question, text)

import whisper
import google.generativeai as genai
import json
import time
from dotenv import load_dotenv
import os
import re
import subprocess
import tempfile

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
WHISPER_MODEL = os.getenv("WHISPER_MODEL", "small")

print("Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")
whisper_model = whisper.load_model(WHISPER_MODEL)
print(f"âœ… Whisper ëª¨ë¸ ë¡œë”© ì™„ë£Œ (model={WHISPER_MODEL})")

# Gemini ì„¤ì • (JSONë§Œ ë°›ë„ë¡)
genai.configure(api_key=GOOGLE_API_KEY)
generation_config = {
    "temperature": 0.3,
    "max_output_tokens": 1024,
    "response_mime_type": "application/json",
}
gemini_model = genai.GenerativeModel(
    model_name="gemini-2.0-flash-001",
    generation_config=generation_config
)

TARGET_KEYS = ["feedback", "confidence", "tone", "resilience", "good", "bad"]

def _coerce_int(v, default=0, lo=0, hi=100):
    try:
        x = int(round(float(v)))
        return max(lo, min(hi, x))
    except:
        return default

def _extract_json(text: str) -> str:
    """ì½”ë“œíœìŠ¤/ì•ë’¤ êµ°ë”ë”ê¸° ì œê±° í›„ JSON ë³¸ë¬¸ë§Œ ì¶”ì¶œ"""
    s = (text or "").strip()
    if s.startswith("```"):
        s = re.sub(r"^```(?:json)?\s*", "", s)
        s = re.sub(r"\s*```$", "", s).strip()
    i, j = s.find("{"), s.rfind("}")
    return s[i:j+1] if i != -1 and j != -1 and j > i else s

def _ensure_feedback_schema(d: dict) -> dict:
    """Geminiê°€ ë°˜í™˜í•œ êµ¬ì¡°ë¥¼ ìš°ë¦¬ê°€ ì›í•˜ëŠ” 6í‚¤ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”."""
    # 1ï¸âƒ£ overallë¥˜ í”¼ë“œë°±
    feedback = (
        d.get("feedback") or
        d.get("overall_feedback") or
        d.get("overall") or
        d.get("summary") or
        ""
    )
    feedback = str(feedback).strip() or "í•µì‹¬ ì‚¬ë¡€ë¥¼ ë¨¼ì € ì œì‹œí•˜ë©´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤."

    # 2ï¸âƒ£ ê¸ì •ì  í”¼ë“œë°± í›„ë³´
    good = d.get("good") or ""
    if not good:
        pos = d.get("positive_aspects")
        if isinstance(pos, dict):
            good = " ".join([str(v) for v in pos.values() if v])
        elif isinstance(pos, list):
            good = " ".join([str(x) for x in pos if x])
    good = str(good).strip() or "êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì˜ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤."

    # 3ï¸âƒ£ ë³´ì™„ì  í›„ë³´
    bad = d.get("bad") or ""
    if not bad:
        neg = d.get("areas_for_improvement") or d.get("specific_feedback")
        if isinstance(neg, dict):
            bad = " ".join([str(v) for v in neg.values() if v])
        elif isinstance(neg, list):
            bad = " ".join([str(x) for x in neg if x])
    bad = str(bad).strip() or "ë‹µë³€ì´ ë‹¤ì†Œ ì¥í™©í–ˆìŠµë‹ˆë‹¤."

    # 4ï¸âƒ£ ìˆ˜ì¹˜ í•„ë“œ
    confidence = _coerce_int(d.get("confidence", d.get("overall_score", 65)), 65)
    tone = _coerce_int(d.get("tone", 70), 70)
    resilience = _coerce_int(d.get("resilience", 70), 70)

    result = {
        "feedback": feedback,
        "confidence": confidence,
        "tone": tone,
        "resilience": resilience,
        "good": good,
        "bad": bad
    }
    return {k: result[k] for k in TARGET_KEYS}

def _extract_audio_to_wav16(video_path: str) -> str:
    """ffmpegë¡œ 16kHz mono wav ì¶”ì¶œ"""
    try:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        tmp.close()
        subprocess.run(
            ["ffmpeg", "-y", "-i", video_path, "-vn",
             "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", tmp.name],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True
        )
        return tmp.name
    except Exception:
        return video_path

def transcribe_audio_with_whisper(audio_or_video_path: str):
    print("ğŸ§ Whisper ë³€í™˜ ì‹œì‘...")
    start = time.time()
    try:
        path = _extract_audio_to_wav16(audio_or_video_path)
        result = whisper_model.transcribe(path, language="ko", fp16=False)
        elapsed = round(time.time() - start, 2)
        print(f"âœ… Whisper ë³€í™˜ ì™„ë£Œ ({elapsed}ì´ˆ)")
        if path != audio_or_video_path and os.path.exists(path):
            os.unlink(path)
        return result["text"]
    except Exception as e:
        print(f"âŒ Whisper ì˜¤ë¥˜: {e}")
        return None

def generate_feedback_with_gemini(question, answer):
    print("ğŸ§  Gemini í”¼ë“œë°± ìƒì„± ì¤‘...")
    start = time.time()

    prompt = f"""
ì•„ë˜ ë©´ì ‘ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í‰ê°€í•˜ì„¸ìš”.
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. 
í‚¤ëŠ” ë‹¤ìŒ 6ê°œë§Œ í¬í•¨í•©ë‹ˆë‹¤: feedback, confidence, tone, resilience, good, bad.

ë©´ì ‘ ì§ˆë¬¸: "{question}"
ë©´ì ‘ì ë‹µë³€: "{answer}"

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
{{
  "feedback": "í•µì‹¬ ì‚¬ë¡€ë¥¼ ë¨¼ì € ì œì‹œí•˜ë©´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.",
  "confidence": 75,
  "tone": 68,
  "resilience": 80,
  "good": "êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì˜ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.",
  "bad": "ë‹µë³€ì´ ë‹¤ì†Œ ì¥í™©í–ˆìŠµë‹ˆë‹¤."
}}

ì œì•½:
- ì˜¤ì§ ìœ„ 6ê°œ í‚¤ë§Œ í¬í•¨.
- ì½”ë“œ ë¸”ë¡( ``` ) ì¶œë ¥ ê¸ˆì§€.
- JSON ì™¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.
- feedbackì€ ë°˜ë“œì‹œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ëœ ì „ì²´ í‰ê°€ ë¬¸ì¥.
"""

    raw = ""
    try:
        res = gemini_model.generate_content(prompt)
        raw = (res.text or "").strip()
        body = _extract_json(raw)
        parsed = json.loads(body)
    except Exception as e:
        print(f"âš ï¸ 1ì°¨ íŒŒì‹± ì‹¤íŒ¨, ë³´ì • ì‹œë„: {e}")
        try:
            body = _extract_json(raw)
            parsed = json.loads(body)
        except Exception as e2:
            print(f"âŒ 2ì°¨ íŒŒì‹± ì‹¤íŒ¨: {e2}")
            elapsed = round(time.time() - start, 2)
            print(f"âœ… Gemini ê¸°ë³¸ê°’ ë°˜í™˜ ({elapsed}ì´ˆ)")
            return {
                "feedback": "í•µì‹¬ ì‚¬ë¡€ë¥¼ ë¨¼ì € ì œì‹œí•˜ë©´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.",
                "confidence": 65,
                "tone": 70,
                "resilience": 70,
                "good": "êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì˜ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.",
                "bad": "ë‹µë³€ì´ ë‹¤ì†Œ ì¥í™©í–ˆìŠµë‹ˆë‹¤."
            }

    final_dict = _ensure_feedback_schema(parsed)
    elapsed = round(time.time() - start, 2)
    print(f"âœ… Gemini í”¼ë“œë°± ì™„ë£Œ ({elapsed}ì´ˆ) -> {final_dict}")
    return final_dict

def run_interview_feedback_service(audio_or_video_path, interview_question):
    text = transcribe_audio_with_whisper(audio_or_video_path)
    if not text:
        return {"feedback": "ìŒì„± ë³€í™˜ ì‹¤íŒ¨", "confidence": 0, "tone": 0, "resilience": 0, "good": "", "bad": ""}
    print(f"ğŸ—£ï¸ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì¼ë¶€: {text[:100]}...")
    return generate_feedback_with_gemini(interview_question, text)
